\chapter{Related Work}

\section{Introduction to literature review}
The development of AI-powered diagnostic and decision support tools is rapidly transforming  healthcare. Recent innovations in natural language processing (NLP) and computer vision (CV) demonstrate great potential in providing preliminary diagnoses, streamlining referrals, and analyzing medical images – directly addressing accessibility and patient empowerment challenges. However, this emergent field also reveals hurdles in effectively harnessing AI, notably regarding  error handling, model transparency, and the need for rigorous testing before broader applications.

Current AI-based symptom checkers and early-stage diagnostic tools have gained popularity. Projects integrating language models (LMs) and medical knowledge graphs highlight the possibilities in this space ("Leveraging a Medical Knowledge Graph...", "ClinicalGPT ...", "Med-HALT...") These works focus on improving NLP performance for medical contexts but also underscore the challenge of combating 'hallucinations' (errors generated by LLMs). Addressing these inaccuracies through techniques like fine-tuning or prompting while preserving reliability for clinical use remains a vital research focus.

In the realm of medical image analysis, convolutional neural networks (CNNs) are revolutionizing diagnosis, exemplified by their ability to detect pneumonia from chest X-rays with an accuracy that rivals specialists ("CheXNet..."). Furthermore, deep learning approaches to automate the segmentation of anatomical regions, such as the lungs,  ("Automatic Lung Segmentation...") improve workflow efficiency.

The development of referral systems reliant on AI is a further promising area. These systems could automate patient triage and reduce burdens on healthcare providers. To fully realize the potential of these applications, it is imperative to establish rigorous evaluation mechanisms alongside explainable outputs that support trustworthy and transparent decision-making.

This literature review will provide a critical analysis of state-of-the-art AI solutions in areas closely related to the Medibot project. Key focuses will include:


\begin{itemize}
    \item Approaches to AI-powered symptom analysis and preliminary diagnosis
    \item Computer vision applications for medical image analysis
    \item AI-based patient referral systems
    \item Crucial areas of concern such as bias, lack of transparency, and potential errors
\end{itemize}

The goal of this review is to position Medibot within the existing landscape, establish best practices,  and illuminate areas where the project can contribute to this rapidly evolving field of healthcare innovation.


\section{Historical Perspective}
While recent advances might make it seem like a burgeoning field, the concept of harnessing computers for medical diagnosis dates back to the 1970s with the advent of expert systems such as MYCIN. These rule-based systems relied on the encoding of medical knowledge and logical inferences but faced limitations in scalability and the ability to handle uncertainty.

A subsequent shift towards statistical and machine learning approaches fueled progress, but computational bottlenecks initially constrained wide adoption. Developments in neural networks during the 1990s set the stage, but it wasn't until the early 2010s, coinciding with the advent of deep learning and vast improvements in computing power, that AI began to see breakthroughs in medical image analysis.

Significant achievements, such as the success of convolutional neural networks (CNNs) in large-scale image classification (e.g., ImageNet), spurred research into adapting these techniques for diagnosing conditions like pneumonia from chest X-rays. In parallel, natural language processing (NLP) has progressed significantly.  While earlier NLP focused on rule-based parsing, new models leveraging word embeddings and neural networks enabled better contextual understanding, leading to more nuanced approaches to symptom analysis.

Recent years have witnessed a confluence of factors propelling healthcare AI research.  Massive datasets, cloud computing, and advanced language models (e.g., GPT-3) have enabled a new wave of AI-powered diagnostic assistants and decision-support tools. Despite their promise, it's important to note that healthcare AI remains a field grappling with potential risks including bias, hallucinations, and the need for rigorous, real-world testing before wide-scale implementation.

\section{Current State of the Art}

The field of AI-powered medical diagnosis is evolving rapidly, with several approaches offering promising results:

\begin{itemize}
    \item \textbf{Symptom Checkers and Preliminary Diagnosis: }Systems like Ada Health, Healthily, Sensely,  and Infermedica illustrate the growing reliance on  AI-guided questionnaires and chatbots for symptom analysis.  Despite this progress, limitations exist – they often lack open conversation capabilities, cannot process medical images, and primarily address diagnoses in singular domains without multi-stage support.
    \item \textbf{Medical Image Analysis: } Convolutional neural networks (CNNs) are transforming  medical image analysis.   The success of systems like CheXNet in diagnosing pneumonia showcases their potential for accurate disease detection from medical images.  However, accurate segmentation of regions of interest (like the lungs) can be challenging, especially in cases with abnormalities or occlusions.
    \item \textbf{Natural Language Processing (NLP): }   The recent advent of large language models (LLMs) has revolutionized natural language understanding. These models are increasingly demonstrating capability for medical tasks when finetuned and enhanced with domain-specific knowledge. While showing progress in extracting information from medical records or research papers, handling the subtleties of patient-reported experiences remains a challenge.
\end{itemize}

\section{Medibot's Contributions}
The Medibot project aims to address several of the limitations observed in existing AI-powered diagnostic solutions. Key potential innovations include:

\begin{itemize}
    \item \textbf{Flexible NLP Input: } Medibot will process both open-ended symptom descriptions and engage in questionnaire-style interaction, catering to diverse preferences and providing additional avenues for understanding the patient's concerns.
    \item \textbf{Medical Image Integration: } Image analysis with CV techniques will enhance Medibot's diagnostic capabilities while helping streamline workflows for users who have the ability to upload relevant images.
    \item \textbf{Adaptive Referral System: } Medibot will not simply deliver isolated diagnoses but rather intelligently guide patients to suitable specialists or appropriate departments for further care, improving outcomes by fostering continuity of care.
\end{itemize}

